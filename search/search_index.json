{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Computer Vision is an exciting new field with the recent advances in deep learning. This documentation serves to compile knowledge acquired through various courses and online readings. Note that I do not claim copyright over any of these code, and you may attribute any of the resources I tagged to them instead.","title":"Introduction"},{"location":"#introduction","text":"Computer Vision is an exciting new field with the recent advances in deep learning. This documentation serves to compile knowledge acquired through various courses and online readings. Note that I do not claim copyright over any of these code, and you may attribute any of the resources I tagged to them instead.","title":"Introduction"},{"location":"basics/","text":"Basics of Images Convert to Array Using Numpy import numpy as np import matplotlib.pyplot as plt imgArr = np . asarray ( 'imagepath' ) plt . imshow ( pic_arr ) Using OpenCV import cv2 imgArr = cv2 . imread ( 'imagepath' ) cv2 . imshow ( 'image' , img ) # Wait for something on keyboard to be pressed to close window. # 0 refers to 0 miliseconds of waiting cv2 . waitKey ( 0 ) From base64 string import base64 import cv2 npArr = np . fromstring ( base64 . b64decode ( encodedImage ), np . uint8 ) imgArr = cv2 . imdecode ( npArr , cv2 . IMREAD_ANYCOLOR ) Saving Images cv2 . imwrite ( 'my_new_picture.jpg' , imgArr ) Drawing on Images One of the most important reason to draw on images is to draw bounding boxes representing the prediction output. rectangles # pt1 = top left # pt2 = bottom right cv2 . rectangle ( imgArr , pt1 = ( 384 , 0 ), pt2 = ( 510 , 128 ), \\ color = ( 0 , 255 , 0 ), thickness = 5 ) Here's a typical example function from xiaochus's YOLO on how it is used. def draw ( image , boxes , scores , classes , all_classes ): '''Draw the boxes on the image. Argument: image: original image. boxes: ndarray, boxes of objects. classes: ndarray, classes of objects. scores: ndarray, scores of objects. all_classes: all classes name. ''' for box , score , cl in zip ( boxes , scores , classes ): x , y , w , h = box top = max ( 0 , np . floor ( x + 0.5 ) . astype ( int )) left = max ( 0 , np . floor ( y + 0.5 ) . astype ( int )) right = min ( image . shape [ 1 ], np . floor ( x + w + 0.5 ) . astype ( int )) bottom = min ( image . shape [ 0 ], np . floor ( y + h + 0.5 ) . astype ( int )) cv2 . rectangle ( image , ( top , left ), ( right , bottom ), ( 255 , 0 , 0 ), 2 ) cv2 . putText ( image , '{0} {1:.2f}' . format ( all_classes [ cl ], score ), ( top , left - 6 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 0 , 255 ), 1 , cv2 . LINE_AA ) print ( 'class: {0}, score: {1:.2f}' . format ( all_classes [ cl ], score )) print ( 'box coordinate x,y,w,h: {0}' . format ( box )) Wait & Break This is not exactly pythonic, so it means it is not as easy to decipher. 0xFF is an 8 bit binary mask that forces the result from waitKey() to be an integer of maximum 255, which is what a character in the keyboard can go till. ord(char) returns the character in integers which will also be of maximum 255. Hence by comparing the integer to the ord(char) value, we can check for a key pressed event and break the loop. # stop when character \"q\" is pressed if cv2 . waitKey ( 0 ) & 0xFF == ord ( 'q' ): break # stop when \"ESC\" key is pressed if cv2 . waitKey ( 20 ) & 0xFF == 27 : break # Once script is done, its usually good practice to call this line # It closes all windows (just in case you have multiple windows called) cv2 . destroyAllWindows ()","title":"Image Basics"},{"location":"basics/#basics-of-images","text":"","title":"Basics of Images"},{"location":"basics/#convert-to-array","text":"Using Numpy import numpy as np import matplotlib.pyplot as plt imgArr = np . asarray ( 'imagepath' ) plt . imshow ( pic_arr ) Using OpenCV import cv2 imgArr = cv2 . imread ( 'imagepath' ) cv2 . imshow ( 'image' , img ) # Wait for something on keyboard to be pressed to close window. # 0 refers to 0 miliseconds of waiting cv2 . waitKey ( 0 ) From base64 string import base64 import cv2 npArr = np . fromstring ( base64 . b64decode ( encodedImage ), np . uint8 ) imgArr = cv2 . imdecode ( npArr , cv2 . IMREAD_ANYCOLOR )","title":"Convert to Array"},{"location":"basics/#saving-images","text":"cv2 . imwrite ( 'my_new_picture.jpg' , imgArr )","title":"Saving Images"},{"location":"basics/#drawing-on-images","text":"One of the most important reason to draw on images is to draw bounding boxes representing the prediction output. rectangles # pt1 = top left # pt2 = bottom right cv2 . rectangle ( imgArr , pt1 = ( 384 , 0 ), pt2 = ( 510 , 128 ), \\ color = ( 0 , 255 , 0 ), thickness = 5 ) Here's a typical example function from xiaochus's YOLO on how it is used. def draw ( image , boxes , scores , classes , all_classes ): '''Draw the boxes on the image. Argument: image: original image. boxes: ndarray, boxes of objects. classes: ndarray, classes of objects. scores: ndarray, scores of objects. all_classes: all classes name. ''' for box , score , cl in zip ( boxes , scores , classes ): x , y , w , h = box top = max ( 0 , np . floor ( x + 0.5 ) . astype ( int )) left = max ( 0 , np . floor ( y + 0.5 ) . astype ( int )) right = min ( image . shape [ 1 ], np . floor ( x + w + 0.5 ) . astype ( int )) bottom = min ( image . shape [ 0 ], np . floor ( y + h + 0.5 ) . astype ( int )) cv2 . rectangle ( image , ( top , left ), ( right , bottom ), ( 255 , 0 , 0 ), 2 ) cv2 . putText ( image , '{0} {1:.2f}' . format ( all_classes [ cl ], score ), ( top , left - 6 ), cv2 . FONT_HERSHEY_SIMPLEX , 0.6 , ( 0 , 0 , 255 ), 1 , cv2 . LINE_AA ) print ( 'class: {0}, score: {1:.2f}' . format ( all_classes [ cl ], score )) print ( 'box coordinate x,y,w,h: {0}' . format ( box ))","title":"Drawing on Images"},{"location":"basics/#wait-break","text":"This is not exactly pythonic, so it means it is not as easy to decipher. 0xFF is an 8 bit binary mask that forces the result from waitKey() to be an integer of maximum 255, which is what a character in the keyboard can go till. ord(char) returns the character in integers which will also be of maximum 255. Hence by comparing the integer to the ord(char) value, we can check for a key pressed event and break the loop. # stop when character \"q\" is pressed if cv2 . waitKey ( 0 ) & 0xFF == ord ( 'q' ): break # stop when \"ESC\" key is pressed if cv2 . waitKey ( 20 ) & 0xFF == 27 : break # Once script is done, its usually good practice to call this line # It closes all windows (just in case you have multiple windows called) cv2 . destroyAllWindows ()","title":"Wait &amp; Break"},{"location":"install/","text":"Installation Installations for computer vision can prove to tricky, from nvidia GPU to certain libraries compiled from other languages, it can turn out to extremely time-consuming. OpenCV Using pip install opencv-python installs the official version of cv2. However, there are some contribution libraries which are missing because of certain issues; to install a complete package, use pip install opencv-contrib-python instead.","title":"Installation"},{"location":"install/#installation","text":"Installations for computer vision can prove to tricky, from nvidia GPU to certain libraries compiled from other languages, it can turn out to extremely time-consuming.","title":"Installation"},{"location":"install/#opencv","text":"Using pip install opencv-python installs the official version of cv2. However, there are some contribution libraries which are missing because of certain issues; to install a complete package, use pip install opencv-contrib-python instead.","title":"OpenCV"},{"location":"transfer_learning/","text":"Transfer Learning For CNN, because of the huge research done, and the complexity in architecture, we can use existing ones. The latest one is EfficientNet by Google which can achieve higher accuracy with fewer parameters. For transfer learning for image recognition, the defacto is imagenet, whereby we can specify it under the weights argument. import efficientnet.tfkeras as efn def model ( input_shape , classes ): ''' transfer learning from imagenet's weights, using Google's efficientnet7 architecture top layer (include_top) is removed as the number of classes is changed ''' base = efn . EfficientNetB7 ( input_shape = input_shape , weights = 'imagenet' , include_top = False ) model = Sequential () model . add ( base ) model . add ( GlobalAveragePooling2D ()) model . add ( Dense ( classes , activation = 'softmax' )) model . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) return model # alternatively... def model ( input_shape , classes ): model = efn . EfficientNetB3 ( input_shape = input_shape , weights = 'imagenet' , include_top = False ) x = model . output x = Flatten ()( x ) x = Dropout ( 0.5 )( x ) output_layer = Dense ( classes , activation = 'softmax' )( x ) model = Model ( inputs = model . input , outputs = output_layer ) model . compile ( optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) return model","title":"Transfer Learning"},{"location":"transfer_learning/#transfer-learning","text":"For CNN, because of the huge research done, and the complexity in architecture, we can use existing ones. The latest one is EfficientNet by Google which can achieve higher accuracy with fewer parameters. For transfer learning for image recognition, the defacto is imagenet, whereby we can specify it under the weights argument. import efficientnet.tfkeras as efn def model ( input_shape , classes ): ''' transfer learning from imagenet's weights, using Google's efficientnet7 architecture top layer (include_top) is removed as the number of classes is changed ''' base = efn . EfficientNetB7 ( input_shape = input_shape , weights = 'imagenet' , include_top = False ) model = Sequential () model . add ( base ) model . add ( GlobalAveragePooling2D ()) model . add ( Dense ( classes , activation = 'softmax' )) model . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) return model # alternatively... def model ( input_shape , classes ): model = efn . EfficientNetB3 ( input_shape = input_shape , weights = 'imagenet' , include_top = False ) x = model . output x = Flatten ()( x ) x = Dropout ( 0.5 )( x ) output_layer = Dense ( classes , activation = 'softmax' )( x ) model = Model ( inputs = model . input , outputs = output_layer ) model . compile ( optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) return model","title":"Transfer Learning"},{"location":"videos/","text":"Videos From Webcam import cv2 # Connects to your computer's default camera cap = cv2 . VideoCapture ( 0 ) while True : # Capture frame-by-frame ret , frame = cap . read () # Our operations on the frame come here gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) cv2 . imshow ( 'frame' , gray ) # quit with \"q\" if cv2 . waitKey ( 1 ) & 0xFF == ord ( 'q' ): break # When everything done, release the capture and destroy the windows cap . release () cv2 . destroyAllWindows () From File import cv2 import time cap = cv2 . VideoCapture ( '../DATA/video_capture.mp4' ) # FRAMES PER SECOND fps = 25 # check for video file if cap . isOpened () == False : print ( \"Error opening the video file\" ) # While the video is opened while cap . isOpened (): # Read the video file ret , frame = cap . read () # If we got frames, show them. if ret == True : # Display the frame at same frame rate of recording time . sleep ( 1 / fps ) cv2 . imshow ( 'frame' , frame ) if cv2 . waitKey ( 25 ) & 0xFF == ord ( 'q' ): break # automatically break this whole loop if the video is over else : break cap . release () # Closes all the frames cv2 . destroyAllWindows ()","title":"Videos"},{"location":"videos/#videos","text":"","title":"Videos"},{"location":"videos/#from-webcam","text":"import cv2 # Connects to your computer's default camera cap = cv2 . VideoCapture ( 0 ) while True : # Capture frame-by-frame ret , frame = cap . read () # Our operations on the frame come here gray = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2GRAY ) cv2 . imshow ( 'frame' , gray ) # quit with \"q\" if cv2 . waitKey ( 1 ) & 0xFF == ord ( 'q' ): break # When everything done, release the capture and destroy the windows cap . release () cv2 . destroyAllWindows ()","title":"From Webcam"},{"location":"videos/#from-file","text":"import cv2 import time cap = cv2 . VideoCapture ( '../DATA/video_capture.mp4' ) # FRAMES PER SECOND fps = 25 # check for video file if cap . isOpened () == False : print ( \"Error opening the video file\" ) # While the video is opened while cap . isOpened (): # Read the video file ret , frame = cap . read () # If we got frames, show them. if ret == True : # Display the frame at same frame rate of recording time . sleep ( 1 / fps ) cv2 . imshow ( 'frame' , frame ) if cv2 . waitKey ( 25 ) & 0xFF == ord ( 'q' ): break # automatically break this whole loop if the video is over else : break cap . release () # Closes all the frames cv2 . destroyAllWindows ()","title":"From File"}]}